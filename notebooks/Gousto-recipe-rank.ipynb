{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gousto Recipe Rank Forecasting: MSc Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import os\n",
    "import json\n",
    "import shap\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.decomposition import PCA\n",
    "import optuna\n",
    "import optuna.visualization as vis\n",
    "import time\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout, Input, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data load\n",
    "directory = os.getcwd()\n",
    "file_path = os.path.join(directory, '..', 'data', 'extended_training_df_619.json')\n",
    "\n",
    "# Read JSON file\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "fields = [field['name'] for field in data['schema']['fields'] if field['name'] != 'index']\n",
    "records = data.get('data', [])\n",
    "\n",
    "# Convert to Pandas DataFrame\n",
    "df = pd.DataFrame(records, columns=fields)\n",
    "df['item_id'] = pd.to_numeric(df['item_id'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Transformations\n",
    "df_full = df.copy()\n",
    "\n",
    "# Remove short term model features of uptake at lead day and differences\n",
    "columns_to_remove = df.filter(like=\"uptake_at_lead_day\").columns\n",
    "df.drop(columns=columns_to_remove, inplace=True)\n",
    "\n",
    "# Remove contamination outlier feature as this is not present in test data\n",
    "df.drop(columns=['contamination_outlier'], inplace=True)\n",
    "\n",
    "# Create recipe rank percentile column (still called recipe rank)\n",
    "df['recipe_rank'] = df.groupby('menu_week')['recipe_uptake'].rank(method='first', ascending=False) - 1\n",
    "df['recipe_rank'] = df['recipe_rank'].astype(int)\n",
    "# Drop recipe uptake column\n",
    "df = df.drop(columns=['recipe_uptake'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "# Create df before PCA, removing target and item_id columns\n",
    "df_pca_pre = df.drop(columns=['recipe_rank', 'item_id'])\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "df_pca_pre_scaled = scaler.fit_transform(df_pca_pre)\n",
    "\n",
    "# Perform PCA to retain 95% variance\n",
    "pca = PCA(n_components=0.95)\n",
    "df_pca_transformed = pca.fit_transform(df_pca_pre_scaled)\n",
    "\n",
    "# Convert the PCA result back to a DataFrame\n",
    "pca_columns = [f'PC{i+1}' for i in range(df_pca_transformed.shape[1])]\n",
    "df_pca = pd.DataFrame(df_pca_transformed, columns=pca_columns, index=df_pca_pre.index)\n",
    "\n",
    "# Combine the results back with the untouched columns and menu_week\n",
    "df_final = pd.concat([df_pca, df[['menu_week', 'item_id', 'recipe_rank']]], axis=1)\n",
    "\n",
    "# Plot Explained Variance\n",
    "explained_variance_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, marker='o', linestyle='--')\n",
    "plt.axhline(y=0.9, color='r', linestyle='--', label='90% Variance')\n",
    "plt.axhline(y=0.95, color='g', linestyle='--', label='95% Variance')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Explained Variance vs Components')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to normalise data\n",
    "def normalize_data(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Convert back to DataFrame to maintain the index\n",
    "    X_train_scaled = pd.DataFrame(X_train_scaled, index=X_train.index, columns=X_train.columns)\n",
    "    X_test_scaled = pd.DataFrame(X_test_scaled, index=X_test.index, columns=X_test.columns)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "# Function for custom time series cross validation split, for the final 3 menu weeks\n",
    "def custom_time_series_cv(X_train, n_validation_weeks=3):\n",
    "    validation_weeks = X_train['menu_week'].unique()[-n_validation_weeks:]\n",
    "    for valid_week in validation_weeks:\n",
    "        train_df = X_train[X_train['menu_week'] < valid_week]\n",
    "        valid_df = X_train[X_train['menu_week'] == valid_week]\n",
    "        yield train_df.index, valid_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate predictions and plot error bars for statistical algorithms\n",
    "def evaluate_predictions_algos(all_errors, method, weeks_before_target=8, total_week_iterations=20):\n",
    "    min_y_range = 0.05\n",
    "    average_errors, lower_bound_errors, upper_bound_errors = [], [], []\n",
    "\n",
    "    for i in range(weeks_before_target):\n",
    "        errors_for_week = [iteration[i]['mean_absolute_error'] for iteration in all_errors if i < len(iteration)]\n",
    "        if errors_for_week:\n",
    "            average_error = np.mean(errors_for_week)\n",
    "            sem = np.std(errors_for_week) / np.sqrt(len(errors_for_week))\n",
    "            ci = 1.96 * sem  # 95% confidence interval\n",
    "\n",
    "            # Store results\n",
    "            average_errors.append({'week_before_target': weeks_before_target - i, 'average_mean_absolute_error': average_error})\n",
    "            lower_bound_errors.append(average_error - ci)\n",
    "            upper_bound_errors.append(average_error + ci)\n",
    "\n",
    "    print(f\"Method: {method} | MAEs {average_errors}\")\n",
    "    # Convert to DataFrame for easier access\n",
    "    average_errors_df = pd.DataFrame(average_errors)\n",
    "    avg_errors_array = average_errors_df['average_mean_absolute_error'].to_numpy()\n",
    "\n",
    "    # Calculate y-limits and add margins if necessary\n",
    "    y_min, y_max = min(lower_bound_errors), max(upper_bound_errors)\n",
    "    y_range = y_max - y_min\n",
    "    if y_range < min_y_range:\n",
    "        margin = min_y_range * 0.5\n",
    "        y_min = np.mean([y_min, y_max]) - margin\n",
    "        y_max = np.mean([y_min, y_max]) + margin\n",
    "    else:\n",
    "        margin = y_range * 0.1\n",
    "        y_min -= margin\n",
    "        y_max += margin\n",
    "\n",
    "    # Plot results\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(average_errors_df['week_before_target'], avg_errors_array, marker='o', color='b', linestyle='-', label='Average MAE', lw=2, markersize=6)\n",
    "    plt.fill_between(average_errors_df['week_before_target'], lower_bound_errors, upper_bound_errors, color='b', alpha=0.2, label='95% Confidence Interval')\n",
    "    plt.ylim([y_min, y_max])\n",
    "    plt.xlabel('Weeks Before Target', fontsize=14)\n",
    "    plt.ylabel('Average Mean Absolute Error', fontsize=14)\n",
    "    plt.title(f'{method}: Average MAE over {weeks_before_target} Weeks Before Target Across {total_week_iterations} Iterations', fontsize=16)\n",
    "    plt.gca().invert_xaxis()\n",
    "    plt.gca().yaxis.set_major_formatter(ScalarFormatter(useOffset=False))\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.7, alpha=0.7)\n",
    "    plt.legend(loc='upper right', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate predictions and plot error bars for supervised learning models\n",
    "def evaluate_predictions(all_errors, method, weeks_before_target=8, total_week_iterations=20):\n",
    "    min_y_range = 0.05\n",
    "    average_errors, lower_bound_errors, upper_bound_errors = [], [], []\n",
    "\n",
    "    for i in range(1, weeks_before_target + 1):\n",
    "        errors_for_week = all_errors.get(i, [])\n",
    "        if errors_for_week:\n",
    "            average_error = np.mean(errors_for_week)\n",
    "            sem = np.std(errors_for_week) / np.sqrt(len(errors_for_week))\n",
    "            ci = 1.96 * sem  # 95% confidence interval\n",
    "\n",
    "            # Store results\n",
    "            average_errors.append({'week_before_target': i, 'average_mean_absolute_error': average_error})\n",
    "            lower_bound_errors.append(average_error - ci)\n",
    "            upper_bound_errors.append(average_error + ci)\n",
    "    print(f\"Method: {method} | MAEs {average_errors}\")\n",
    "    average_errors_df = pd.DataFrame(average_errors)\n",
    "    avg_errors_array = average_errors_df['average_mean_absolute_error'].to_numpy()\n",
    "\n",
    "    # Calculate y-limits and add margins if necessary\n",
    "    y_min, y_max = min(lower_bound_errors), max(upper_bound_errors)\n",
    "    y_range = y_max - y_min\n",
    "    if y_range < min_y_range:\n",
    "        margin = min_y_range * 0.5\n",
    "        y_min = np.mean([y_min, y_max]) - margin\n",
    "        y_max = np.mean([y_min, y_max]) + margin\n",
    "    else:\n",
    "        margin = y_range * 0.1\n",
    "        y_min -= margin\n",
    "        y_max += margin\n",
    "\n",
    "    # Plot results\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(average_errors_df['week_before_target'], avg_errors_array, marker='o', color='b', linestyle='-', label='Average MAE', lw=2, markersize=6)\n",
    "    plt.fill_between(average_errors_df['week_before_target'], lower_bound_errors, upper_bound_errors, color='b', alpha=0.2, label='95% Confidence Interval')\n",
    "    plt.ylim([y_min, y_max])\n",
    "    plt.xlabel('Weeks Before Target', fontsize=14)\n",
    "    plt.ylabel('Average Mean Absolute Error', fontsize=14)\n",
    "    plt.title(f'{method}: Average MAE over {weeks_before_target} Weeks Before Target Across {total_week_iterations} Iterations', fontsize=16)\n",
    "    plt.gca().invert_xaxis()\n",
    "    plt.gca().yaxis.set_major_formatter(ScalarFormatter(useOffset=False))\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.7, alpha=0.7)\n",
    "    plt.legend(loc='upper right', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Algorithms\n",
    "def get_total_average_predictions(X_train, y_train, X_test):\n",
    "    average_value = y_train.mean()\n",
    "    predictions = np.full(X_test.shape[0], average_value)\n",
    "    return pd.Series(predictions, index=X_test.index)\n",
    "\n",
    "def get_last_occurrence_predictions(X_train, y_train, X_test):\n",
    "    default_value = y_train.mean()\n",
    "    last_occurrence_results = {}\n",
    "    for item_id in X_test['item_id']:\n",
    "        X_train_lookup = X_train[X_train['item_id'] == item_id]\n",
    "        if not X_train_lookup.empty:\n",
    "            max_menu_week = X_train_lookup['menu_week'].max()\n",
    "            last_occurrence_results[item_id] = y_train[(X_train['item_id'] == item_id) & (X_train['menu_week'] == max_menu_week)].values[0]\n",
    "        else:\n",
    "            last_occurrence_results[item_id] = default_value\n",
    "    return X_test['item_id'].map(last_occurrence_results)\n",
    "\n",
    "def get_average_occurrence_predictions(X_train, y_train, X_test):\n",
    "    default_value = y_train.mean()\n",
    "    avg_occurrence_results = {}\n",
    "    for item_id in X_test['item_id']:\n",
    "        X_train_lookup = X_train[X_train['item_id'] == item_id]\n",
    "        if not X_train_lookup.empty:\n",
    "            avg_occurrence_results[item_id] = y_train[X_train['item_id'] == item_id].mean()\n",
    "        else:\n",
    "            avg_occurrence_results[item_id] = default_value\n",
    "    return X_test['item_id'].map(avg_occurrence_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "def get_linear_regression_model(X_train, y_train):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM\n",
    "def get_lightgbm_model(X_train, y_train):\n",
    "    params = {\n",
    "        'verbose': -1,\n",
    "        'objective': 'regression',\n",
    "        'metric': 'mae',\n",
    "        'n_estimators': 100,\n",
    "        'learning_rate': 0.2200044953698462,\n",
    "        'max_depth': 18,\n",
    "        'num_leaves': 669,\n",
    "        'min_child_samples': 59,\n",
    "        'min_split_gain': 1.4670533847983645e-06,\n",
    "        'subsample': 0.7382953054809258,\n",
    "        'colsample_bytree': 0.9648983195093089,\n",
    "        'lambda_l1': 4.840165592010454e-07,\n",
    "        'lambda_l2': 0.0025555820497953578,\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1,\n",
    "    }\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "def get_xgboost_model(X_train, y_train):\n",
    "    params = {\n",
    "        'verbosity': 0,\n",
    "        'objective': 'reg:logistic',\n",
    "        'booster': 'gbtree',\n",
    "        'eval_metric': 'mae',\n",
    "        'n_estimators': 100,\n",
    "        'learning_rate': 0.1759631363500291,\n",
    "        'max_depth': 18,\n",
    "        'min_child_weight': 2,\n",
    "        'gamma': 0.0629948621294653,\n",
    "        'subsample': 0.8156395766546685,\n",
    "        'colsample_bytree': 0.5720051923599051,\n",
    "        'colsample_bylevel': 0.8213911771088588,\n",
    "        'lambda': 0.06733986476289976,\n",
    "        'alpha': 0.8232226058749751,\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1,\n",
    "    }\n",
    "    model = xgb.XGBRegressor(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "def get_random_forest_model(X_train, y_train):\n",
    "    params = {\n",
    "        'n_estimators': 100,\n",
    "        'max_depth': None,\n",
    "        'min_samples_split': 4,\n",
    "        'min_samples_leaf': 1,\n",
    "        'max_features': 'log2',\n",
    "        'max_leaf_nodes': None,\n",
    "        'min_weight_fraction_leaf': 0.0,\n",
    "        'max_samples': None,\n",
    "        'criterion': 'friedman_mse',\n",
    "        'min_impurity_decrease': 0.08,\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1,\n",
    "    }\n",
    "    model = RandomForestRegressor(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM Ranker\n",
    "def get_lgbm_ranker_model(X_train, y_train):\n",
    "    group_train = X_train.groupby('menu_week').size().to_list() \n",
    "    params = {\n",
    "        'objective': 'lambdarank',\n",
    "        'metric': 'ndcg',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'max_depth': 13,\n",
    "        'learning_rate': 0.06732857519006756,\n",
    "        'n_estimators': 623,\n",
    "        'min_child_weight': 6.207324113550803,\n",
    "        'min_child_samples': 51,\n",
    "        'subsample': 0.772260146512238,\n",
    "        'subsample_freq': 8,\n",
    "        'colsample_bytree': 0.6959641369551797,\n",
    "        'reg_alpha': 0.0013516164018592264,\n",
    "        'reg_lambda': 0.002763584077083565,\n",
    "        'importance_type': 'split',\n",
    "        'label_gain': 5*list(range(max(group_train))),\n",
    "        'verbose': -1\n",
    "    }\n",
    "    model = lgb.LGBMRanker(**params)\n",
    "    model.fit(X_train, y_train, group=group_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Ranker\n",
    "def get_xgboost_ranker_model(X_train, y_train):\n",
    "    group_train = X_train.groupby('menu_week').size().to_list() \n",
    "    params = {\n",
    "        'objective': 'rank:pairwise',\n",
    "        'eval_metric': 'ndcg',\n",
    "        'learning_rate': 0.1413861549700997,\n",
    "        'max_depth': 6,\n",
    "        'min_child_weight': 17,\n",
    "        'gamma': 1.0529385943580223,\n",
    "        'subsample': 0.9283230260401305,\n",
    "        'colsample_bytree': 0.6587909355240208,\n",
    "        'colsample_bylevel': 0.5063142658549241,\n",
    "        'lambda': 0.008776031157446995,\n",
    "        'alpha': 0.23436060259654692,\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1,\n",
    "        'ndcg_exp_gain': False,\n",
    "        'random_state': 42,\n",
    "    }\n",
    "\n",
    "    num_boost_round = 458\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtrain.set_group(group_train)\n",
    "\n",
    "    model = xgb.train(params, dtrain, num_boost_round=num_boost_round)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoost Ranker\n",
    "def get_catboost_ranker_model(X_train, y_train):\n",
    "    group_train = X_train['menu_week']\n",
    "    \n",
    "    params = {\n",
    "        'learning_rate': 0.3477239622054686,\n",
    "        'depth': 9,\n",
    "        'iterations': 100,\n",
    "        'loss_function': 'PairLogit',\n",
    "        'verbose': False,\n",
    "        'random_seed': 42,\n",
    "        'l2_leaf_reg': 9.360490681305208,\n",
    "        'colsample_bylevel': 0.7863055932866824,\n",
    "        'subsample': 0.9448577817655559,\n",
    "        'bootstrap_type': 'Bernoulli',\n",
    "        'eval_metric': 'NDCG',\n",
    "    }\n",
    "\n",
    "    model = cb.CatBoostRanker(**params)\n",
    "    model.fit(X_train, y_train, group_id=group_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN Model\n",
    "def get_rnn_model(X_train, y_train, epochs=300, batch_size=16, units=64, time_steps=1):\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    \n",
    "    # Reshaping data for RNN: (samples, time_steps, features)\n",
    "    X_train_reshaped = np.reshape(X_train_scaled, (X_train_scaled.shape[0], time_steps, X_train_scaled.shape[1]))\n",
    "\n",
    "    # Build the RNN model\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(time_steps, X_train_scaled.shape[1])))\n",
    "    model.add(SimpleRNN(units=units, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(SimpleRNN(units=units, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=1))\n",
    "\n",
    "    # Compile and fit model\n",
    "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "    model.fit(X_train_reshaped, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "\n",
    "    return model, scaler\n",
    "\n",
    "# LSTM Model\n",
    "def get_lstm_model(X_train, y_train, epochs=300, batch_size=16, units=64, time_steps=1):\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    \n",
    "    # Reshaping data for LSTM: (samples, time_steps, features)\n",
    "    X_train_reshaped = np.reshape(X_train_scaled, (X_train_scaled.shape[0], time_steps, X_train_scaled.shape[1]))\n",
    "\n",
    "    # Build the LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(time_steps, X_train_scaled.shape[1])))\n",
    "    model.add(LSTM(units=units, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=units, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=1))\n",
    "\n",
    "    # Compile and fit model\n",
    "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "    model.fit(X_train_reshaped, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "\n",
    "    return model, scaler\n",
    "\n",
    "# Function to predict both neural network models and scale data\n",
    "def nn_predict(trained_model, X_test, scaler, time_steps=1):\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    X_test_reshaped = np.reshape(X_test_scaled, (X_test_scaled.shape[0], time_steps, X_test_scaled.shape[1]))\n",
    "\n",
    "    y_pred_values = trained_model.predict(X_test_reshaped, verbose=0)\n",
    "    return y_pred_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to tune LightGBM Hyperparameters\n",
    "def tune_lightgbm_hyperparameters(df, start_week, n_splits=5, n_trials=5):\n",
    "    initial_data = df[df['menu_week'] < start_week]\n",
    "    \n",
    "    X = initial_data.drop(columns=['recipe_rank_percentile'])\n",
    "    y = initial_data['recipe_rank_percentile']\n",
    "\n",
    "    def objective(trial):\n",
    "        param = {\n",
    "            'verbosity': -1,\n",
    "            'objective': 'regression',\n",
    "            'metric': 'mae',\n",
    "            'n_estimators': 100,\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0, log=True),\n",
    "            'max_depth': trial.suggest_int('max_depth', 2, 20),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 20, 800),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "            'min_split_gain': trial.suggest_float('min_split_gain', 1e-8, 1.0, log=True),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "            'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
    "            'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1,\n",
    "        }\n",
    "\n",
    "        maes = []\n",
    "        tscv = custom_time_series_cv(X, n_splits)\n",
    "        for train_index, valid_index in tscv:\n",
    "            X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "            y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "\n",
    "            # LightGBM model\n",
    "            model = lgb.LGBMRegressor(**param)\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            preds = model.predict(X_valid)\n",
    "            mae = mean_absolute_error(y_valid, preds)\n",
    "            maes.append(mae)\n",
    "        \n",
    "        return np.mean(maes)\n",
    "\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    vis.plot_param_importances(study).show()\n",
    "    vis.plot_slice(study).show()\n",
    "\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to tune XGBoost Hyperparameters\n",
    "def tune_xgboost_hyperparameters(df, start_week, n_splits=5, n_trials=5):\n",
    "    initial_data = df[df['menu_week'] < start_week]\n",
    "    \n",
    "    X = initial_data.drop(columns=['recipe_rank_percentile'])\n",
    "    y = initial_data['recipe_rank_percentile']\n",
    "\n",
    "    def objective(trial):\n",
    "        param = {\n",
    "            'verbosity': 0,\n",
    "            'objective': 'reg:logistic',\n",
    "            'booster': 'gbtree',\n",
    "            'eval_metric': 'mae',\n",
    "            'n_estimators': trial.suggest_categorical('n_estimators', [int(x) for x in np.linspace(100, 1000, num=10)]),\n",
    "            'learning_rate': 0.1759631363500291,\n",
    "            'max_depth': 18,\n",
    "            'min_child_weight': 2,\n",
    "            'gamma': 0.0629948621294653,\n",
    "            'subsample': 0.8156395766546685,\n",
    "            'colsample_bytree': 0.5720051923599051,\n",
    "            'colsample_bylevel': 0.8213911771088588,\n",
    "            'lambda': 0.06733986476289976,\n",
    "            'alpha': 0.8232226058749751,\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1,\n",
    "        }\n",
    "\n",
    "        maes = []\n",
    "        tscv = custom_time_series_cv(X, n_splits)\n",
    "        for train_index, valid_index in tscv:\n",
    "            X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "            y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "            model = xgb.XGBRegressor(**param)\n",
    "            model.fit(X_train, y_train)\n",
    "            preds = model.predict(X_valid)\n",
    "            mae = mean_absolute_error(y_valid, preds)\n",
    "            maes.append(mae)\n",
    "        return np.mean(maes)\n",
    "\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    \n",
    "    vis.plot_param_importances(study).show()\n",
    "    vis.plot_slice(study).show()\n",
    "    \n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to tune Random Forest Hyperparameters\n",
    "def tune_random_forest_hyperparameters(df, start_week, n_splits=5, n_trials=5):\n",
    "    initial_data = df[df['menu_week'] < start_week]\n",
    "    \n",
    "    X = initial_data.drop(columns=['recipe_rank_percentile'])\n",
    "    y = initial_data['recipe_rank_percentile']\n",
    "\n",
    "    def objective(trial):\n",
    "        param = {\n",
    "            'n_estimators': 100,\n",
    "            'max_depth': trial.suggest_int('max_depth', 10, 100),\n",
    "            'min_samples_split': 2,\n",
    "            'min_samples_leaf': 1,\n",
    "            'max_features': 'log2',\n",
    "            'max_leaf_nodes': None,\n",
    "            'min_weight_fraction_leaf': 0.0,\n",
    "            'max_samples': None,\n",
    "            'criterion': 'friedman_mse',\n",
    "            'min_impurity_decrease': 0.08,\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1,\n",
    "        }\n",
    "\n",
    "        maes = []\n",
    "        tscv = custom_time_series_cv(X, n_splits)\n",
    "        for train_index, valid_index in tscv:\n",
    "            X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "            y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "            model = RandomForestRegressor(**param)\n",
    "            model.fit(X_train, y_train)\n",
    "            preds = model.predict(X_valid)\n",
    "            preds = pd.Series(preds).rank(ascending=True, method='first') / len(preds)\n",
    "            mae = mean_absolute_error(y_valid, preds)\n",
    "            maes.append(mae)\n",
    "        return np.mean(maes)\n",
    "\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    vis.plot_param_importances(study).show()\n",
    "    vis.plot_slice(study).show()\n",
    "    \n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate statistical algorithms\n",
    "def run_evaluation_algos(df, target_week_range, weeks_before_target, training_window=None, method='average_occurrence'):\n",
    "    df = df.copy()\n",
    "    total_week_iterations = len(target_week_range)\n",
    "    all_errors = []\n",
    "    num_models = 0\n",
    "    training_window = max(target_week_range) + 1 if training_window is None else training_window\n",
    "    \n",
    "    method_dict = {\n",
    "    'total_average': get_total_average_predictions,\n",
    "    'last_occurrence': get_last_occurrence_predictions,\n",
    "    'average_occurrence': get_average_occurrence_predictions,\n",
    "    }\n",
    "\n",
    "    df['recipe_rank'] = df.groupby('menu_week')['recipe_rank'].rank(method='first', pct=True, ascending=True)\n",
    "\n",
    "    for max_week in target_week_range:\n",
    "        menu_week_range = range(max_week - weeks_before_target, max_week)\n",
    "        iteration_errors = []\n",
    "        \n",
    "        for menu_week_index in menu_week_range:\n",
    "            start_time = time.time()\n",
    "            num_models += 1\n",
    "\n",
    "            train_df = df[(df['menu_week'] >= max(menu_week_index - training_window, 0)) & (df['menu_week'] <= menu_week_index)]\n",
    "            test_df = df[df['menu_week'] == max_week]\n",
    "\n",
    "            X_train = train_df.drop(columns=['recipe_rank'])\n",
    "            y_train = train_df['recipe_rank']\n",
    "\n",
    "            X_test = test_df.drop(columns=['recipe_rank'])\n",
    "            y_test = test_df['recipe_rank']\n",
    "            \n",
    "            y_pred_values = method_dict[method](X_train, y_train, X_test)\n",
    "            y_pred_values = pd.Series(y_pred_values).rank(ascending=True, method='average') / len(y_pred_values)\n",
    "\n",
    "            mean_absolute_error_value = mean_absolute_error(y_test.values, y_pred_values.values)\n",
    "            iteration_errors.append({'menu_week': menu_week_index, 'mean_absolute_error': mean_absolute_error_value})\n",
    "\n",
    "            current_mean_error = np.mean([error['mean_absolute_error'] for errors in all_errors + [iteration_errors] for error in errors])\n",
    "\n",
    "            time_taken = time.time() - start_time\n",
    "            print(f\"No. of models progress: {num_models}/{weeks_before_target*total_week_iterations} | Rolling MAE: {current_mean_error:.4f} | Estimated Time Left: {(1/60 * time_taken*(weeks_before_target*total_week_iterations - num_models)):.1f} minutes\", end='\\r', flush=True)\n",
    "\n",
    "        all_errors.append(iteration_errors)\n",
    "        \n",
    "    evaluate_predictions_algos(all_errors, method, weeks_before_target, total_week_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate supervised learning models\n",
    "def run_evaluation(df, target_week_range, weeks_before_target, training_window=None, method='xgboost'):\n",
    "    # Copy df to avoid changes to main df\n",
    "    df = df.copy()\n",
    "    # Initialise values for total week interations, training window size and pre-allocation for errors\n",
    "    total_week_iterations = len(target_week_range)\n",
    "    all_errors = {weeks_before: [] for weeks_before in range(1, weeks_before_target + 1)}\n",
    "    training_window = max(target_week_range) + 1 if training_window is None else training_window\n",
    "\n",
    "    # Initialise values for num/total models/inferences\n",
    "    num_models = 0\n",
    "    num_inferences = 0\n",
    "    total_models = weeks_before_target + total_week_iterations - 1\n",
    "    total_inferences = weeks_before_target * total_week_iterations\n",
    "\n",
    "    # dict for methods and corresponding model functions\n",
    "    method_dict = {\n",
    "    'linear_regression': get_linear_regression_model,\n",
    "    'lightgbm': get_lightgbm_model,\n",
    "    'xgboost': get_xgboost_model,\n",
    "    'random_forest': get_random_forest_model,\n",
    "    'lgbm_ranker': get_lgbm_ranker_model,\n",
    "    'xgboost_ranker': get_xgboost_ranker_model,\n",
    "    'catboost_ranker': get_catboost_ranker_model,\n",
    "    'rnn': get_rnn_model,\n",
    "    'lstm': get_lstm_model,\n",
    "    }\n",
    "\n",
    "    # List of methods which require training on rank percentiles\n",
    "    rank_percentile_models = ['linear_regression', 'lightgbm', 'xgboost', 'random_forest', 'catboost_ranker', 'rnn' ,'lstm']\n",
    "\n",
    "    # Target feature engineering of rank percentile models\n",
    "    if method in rank_percentile_models:\n",
    "        df['recipe_rank'] = df.groupby('menu_week')['recipe_rank'].rank(method='first', pct=True, ascending=True)\n",
    "\n",
    "    # Assign model function based on method input\n",
    "    model_func = method_dict[method]\n",
    "    \n",
    "    # Loop over all menu weeks as the max training week\n",
    "    for menu_week_index in range(min(target_week_range) - weeks_before_target, max(target_week_range)):\n",
    "        num_models += 1\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Filter training set for the current range of weeks within training window\n",
    "        train_df = df[(df['menu_week'] >= max(menu_week_index - training_window, 0)) & (df['menu_week'] <= menu_week_index)]\n",
    "        X_train = train_df.drop(columns=['recipe_rank'])\n",
    "        y_train = train_df['recipe_rank']\n",
    "\n",
    "        # Train the model only once for this menu_week_index (using scalar for nn models)\n",
    "        if (method in ['rnn', 'lstm']):\n",
    "            trained_model, scaler = model_func(X_train, y_train)\n",
    "        else: \n",
    "            trained_model = model_func(X_train, y_train)  # Assuming return_model=True returns the trained model\n",
    "\n",
    "        time_taken = time.time() - start_time\n",
    "\n",
    "        # Test on each relevant max_week in the target_week_range\n",
    "        for max_week in target_week_range:\n",
    "            if max_week > menu_week_index >= max_week - weeks_before_target:\n",
    "                num_inferences += 1\n",
    "                # Filter test set for the current max_week\n",
    "                test_df = df[df['menu_week'] == max_week]\n",
    "                X_test = test_df.drop(columns=['recipe_rank'])\n",
    "                y_test = test_df['recipe_rank']\n",
    "\n",
    "                # Predict based on model type\n",
    "                if (method == 'xgboost_ranker'):\n",
    "                    dtest = xgb.DMatrix(X_test)\n",
    "                    y_pred_values = trained_model.predict(dtest)\n",
    "                elif (method in ['rnn', 'lstm']):\n",
    "                    y_pred_values = nn_predict(trained_model, X_test, scaler)\n",
    "                    y_pred_values = y_pred_values.flatten()\n",
    "                else:\n",
    "                    y_pred_values = trained_model.predict(X_test)\n",
    "\n",
    "                # Calculate rank percentile of predictions\n",
    "                y_pred_values = pd.Series(y_pred_values).rank(ascending=True, method='first') / len(y_pred_values)\n",
    "\n",
    "                # Convert test values to percentiles too, if not initially converted and trained upon\n",
    "                if method not in rank_percentile_models:\n",
    "                    y_test = (y_test + 1)/len(y_test)\n",
    "\n",
    "                # Calculate mean absolute error\n",
    "                mean_absolute_error_value = mean_absolute_error(y_test.values, y_pred_values.values)\n",
    "                weeks_before = max_week - menu_week_index\n",
    "                all_errors[weeks_before].append(mean_absolute_error_value)\n",
    "                current_mean_error = np.mean([error for errors in all_errors.values() for error in errors])\n",
    "\n",
    "                print(f\"No. of models progress: {num_models}/{total_models} | No. of inferences progress: {num_inferences}/{total_inferences} | Rolling MAE: {current_mean_error:.4f} | Estimated Time Left: {(1/60 * time_taken*(total_models - num_models)):.1f} minutes\", end='\\r')\n",
    "\n",
    "    evaluate_predictions(all_errors, method, weeks_before_target, total_week_iterations)\n",
    "    return current_mean_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation to output shapley values\n",
    "def run_evaluation_shap(df, target_week_range, weeks_before_target, training_window, method='xgboost'):\n",
    "    df = df.copy()\n",
    "    total_week_iterations = len(target_week_range)\n",
    "    all_errors = {weeks_before: [] for weeks_before in range(1, weeks_before_target + 1)}\n",
    "    training_window = max(target_week_range) + 1 if training_window is None else training_window\n",
    "\n",
    "    # Dictionary to accumulate SHAP values across all weeks and iterations\n",
    "    shap_values_accumulated = pd.DataFrame()\n",
    "\n",
    "    num_models = 0\n",
    "    num_inferences = 0\n",
    "    total_models = weeks_before_target + total_week_iterations - 1\n",
    "    total_inferences = weeks_before_target * total_week_iterations\n",
    "\n",
    "    method_dict = {\n",
    "        'linear_regression': get_linear_regression_model,\n",
    "        'lightgbm': get_lightgbm_model,\n",
    "        'xgboost': get_xgboost_model,\n",
    "        'random_forest': get_random_forest_model,\n",
    "        'lgbm_ranker': get_lgbm_ranker_model,\n",
    "        'xgboost_ranker': get_xgboost_ranker_model,\n",
    "        'catboost_ranker': get_catboost_ranker_model,\n",
    "    }\n",
    "\n",
    "    rank_percentile_models = ['linear_regression', 'lightgbm', 'xgboost', 'random_forest', 'catboost_ranker']\n",
    "\n",
    "    if method in rank_percentile_models:\n",
    "        df['recipe_rank'] = df.groupby('menu_week')['recipe_rank'].rank(method='first', pct=True, ascending=True)\n",
    "\n",
    "    model_func = method_dict[method]\n",
    "    \n",
    "    for menu_week_index in range(min(target_week_range) - weeks_before_target, max(target_week_range)):\n",
    "        num_models += 1\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_df = df[(df['menu_week'] >= max(menu_week_index - training_window, 0)) & (df['menu_week'] <= menu_week_index)]\n",
    "        X_train = train_df.drop(columns=['recipe_rank'])\n",
    "        y_train = train_df['recipe_rank']\n",
    "\n",
    "        trained_model = model_func(X_train, y_train)\n",
    "\n",
    "        if method in ['xgboost', 'lightgbm', 'random_forest', 'xgboost_ranker', 'lgbm_ranker', 'catboost_ranker']:\n",
    "            explainer = shap.TreeExplainer(trained_model)\n",
    "        elif method == 'linear_regression':\n",
    "            explainer = shap.LinearExplainer(trained_model, X_train)\n",
    "        else:\n",
    "            explainer = shap.KernelExplainer(trained_model.predict, X_train)\n",
    "\n",
    "        time_taken = time.time() - start_time\n",
    "\n",
    "        for max_week in target_week_range:\n",
    "            if max_week > menu_week_index >= max_week - weeks_before_target:\n",
    "                num_inferences += 1\n",
    "\n",
    "                test_df = df[df['menu_week'] == max_week]\n",
    "                X_test = test_df.drop(columns=['recipe_rank'])\n",
    "                y_test = test_df['recipe_rank']\n",
    "\n",
    "                if method in ['xgboost_ranker']:\n",
    "                    dtest = xgb.DMatrix(X_test)\n",
    "                    y_pred_values = trained_model.predict(dtest)\n",
    "                elif method in ['lgbm_ranker', 'catboost_ranker']:\n",
    "                    y_pred_values = trained_model.predict(X_test)\n",
    "                else:\n",
    "                    y_pred_values = trained_model.predict(X_test)\n",
    "\n",
    "                y_pred_values = pd.Series(y_pred_values).rank(ascending=True, method='first') / len(y_pred_values)\n",
    "\n",
    "                if method not in rank_percentile_models:\n",
    "                    y_test = (y_test + 1)/len(y_test)\n",
    "\n",
    "                shap_values = explainer.shap_values(X_train)\n",
    "                shap_df = pd.DataFrame(shap_values, columns=X_test.columns)\n",
    "\n",
    "                shap_values_accumulated = shap_values_accumulated.add(shap_df, fill_value=0)\n",
    "\n",
    "                mean_absolute_error_value = mean_absolute_error(y_test.values, y_pred_values.values)\n",
    "                weeks_before = max_week - menu_week_index\n",
    "                all_errors[weeks_before].append(mean_absolute_error_value)\n",
    "                current_mean_error = np.mean([error for errors in all_errors.values() for error in errors])\n",
    "\n",
    "                print(f\"No. of models progress: {num_models}/{total_models} | No. of inferences progress: {num_inferences}/{total_inferences} | Rolling MAE: {current_mean_error:.4f} | Estimated Time Left: {(1/60 * time_taken*(total_models - num_models)):.1f} minutes\", end='\\r')\n",
    "\n",
    "    # Calculate the average SHAP values across all iterations\n",
    "    avg_shap_values = shap_values_accumulated.abs().mean().sort_values(ascending=False)\n",
    "\n",
    "    # Print the top 15 features based on average SHAP values across all iterations\n",
    "    print(\"\\nTop features based on average SHAP values across all weeks and iterations:\")\n",
    "    print(avg_shap_values.head(15))\n",
    "    # Return average SHAP values for further analysis\n",
    "    return avg_shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training window tuning\n",
    "training_window_range = range(100, 500, 50)\n",
    "algorithms = [\n",
    "    # {'name': 'Total Average', 'method': 'total_average'},\n",
    "    # {'name': 'Last Occurrence', 'method': 'last_occurrence'},\n",
    "    # {'name': 'Average Occurrence', 'method': 'average_occurrence'},\n",
    "    # {'name': 'Linear Regression', 'method': 'linear_regression'},\n",
    "    # {'name': 'LightGBM', 'method': 'lightgbm'},\n",
    "    # {'name': 'XGBoost', 'method': 'xgboost'},\n",
    "    # {'name': 'Random Forest', 'method': 'random_forest'},\n",
    "    # {'name': 'LightGBM Ranker', 'method': 'lgbm_ranker'},\n",
    "    # {'name': 'XGBoost Ranker', 'method': 'xgboost_ranker'},\n",
    "    # {'name': 'CatBoost Ranker', 'method': 'catboost_ranker'}\n",
    "]\n",
    "\n",
    "# Dictionary to store the results for each algorithm\n",
    "mae_results = {algo['name']: [] for algo in algorithms}\n",
    "\n",
    "original_max_week = df['menu_week'].max() + 1\n",
    "\n",
    "# Run the evaluation\n",
    "total_week_iterations = 5\n",
    "weeks_before_target = 8\n",
    "target_week_range = range(original_max_week - total_week_iterations, original_max_week)\n",
    "\n",
    "for algo in algorithms:\n",
    "    for training_window in training_window_range:\n",
    "        print(f\"Running {algo['name']} with training window {training_window}\")\n",
    "        if algo['method'] in ['total_average', 'last_occurrence', 'average_occurrence']:\n",
    "            mean_mae = run_evaluation_algos(df, target_week_range, weeks_before_target, training_window, method=algo['method'])\n",
    "        else:\n",
    "            mean_mae = run_evaluation(df, target_week_range, weeks_before_target, training_window, method=algo['method'])\n",
    "        print(f\"Mean MAE = {mean_mae}                                                                                                                                    \")\n",
    "        print(\"\")\n",
    "        mae_results[algo['name']].append(mean_mae)\n",
    "\n",
    "if any(len(mae_values) > 0 for mae_values in mae_results.values()):\n",
    "    # Plot the results if there is data\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    for algo_name, mae_values in mae_results.items():\n",
    "        if mae_values:\n",
    "            plt.plot(training_window_range, mae_values, label=algo_name)\n",
    "\n",
    "    plt.title('Mean MAE vs Training Window Size for Different Algorithms')\n",
    "    plt.xlabel('Training Window Size')\n",
    "    plt.ylabel('Mean MAE')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning\n",
    "original_max_week = df['menu_week'].max() + 1\n",
    "\n",
    "# Run the evaluation\n",
    "total_week_iterations = 52\n",
    "weeks_before_target = 8\n",
    "target_week_range = range(original_max_week - total_week_iterations, original_max_week)\n",
    "\n",
    "# Tuning\n",
    "n_splits = 3\n",
    "n_trials = 150\n",
    "\n",
    "start_week_for_tuning = original_max_week - total_week_iterations - weeks_before_target - n_splits\n",
    "\n",
    "# best_params_lightgbm = tune_lightgbm_hyperparameters(df, start_week_for_tuning, n_splits=n_splits, n_trials=n_trials); print(best_params_lightgbm)\n",
    "# best_params_xgboost = tune_xgboost_hyperparameters(df, start_week_for_tuning, n_splits=n_splits, n_trials=n_trials); print(best_params_xgboost)\n",
    "# best_params_random_forest = tune_random_forest_hyperparameters(df, start_week_for_tuning, n_splits=n_splits, n_trials=n_trials); print(best_params_random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Execution\n",
    "setback = 0\n",
    "original_max_week = df['menu_week'].max() + 1 - setback\n",
    "\n",
    "total_week_iterations = 52\n",
    "weeks_before_target = 8\n",
    "target_week_range = range(original_max_week - total_week_iterations, original_max_week)\n",
    "\n",
    "# print(\"Total Average Algorithm:\"); run_evaluation_algos(df, target_week_range, weeks_before_target, training_window=None, method='total_average'); print(\"\\n\")\n",
    "\n",
    "# print(\"Last Occurrence Algorithm:\"); run_evaluation_algos(df, target_week_range, weeks_before_target, training_window=None, method='last_occurrence'); print(\"\\n\")\n",
    "\n",
    "# print(\"Average Occurrence Algorithm:\"); run_evaluation_algos(df, target_week_range, weeks_before_target, training_window=120, method='average_occurrence'); print(\"\\n\")\n",
    "\n",
    "# print(\"Linear Regression:\"); run_evaluation(df, target_week_range, weeks_before_target, training_window=50, method='linear_regression'); print(\"\\n\")\n",
    "\n",
    "# print(\"LightGBM:\"); run_evaluation(df, target_week_range, weeks_before_target, training_window=100, method='lightgbm'); print(\"\\n\")\n",
    "\n",
    "# print(\"XGBoost:\"); run_evaluation(df, target_week_range, weeks_before_target, training_window=300, method='xgboost'); print(\"\\n\")\n",
    "\n",
    "# print(\"Random Forest:\"); run_evaluation(df, target_week_range, weeks_before_target, training_window=120, method='random_forest'); print(\"\\n\")\n",
    "\n",
    "# print(\"LightGBM Ranker:\") ; run_evaluation(df, target_week_range, weeks_before_target, training_window=180, method='lgbm_ranker'); print(\"\\n\")\n",
    "\n",
    "# print(\"XGBoost Ranker:\") ; run_evaluation(df, target_week_range, weeks_before_target, training_window=300, method='xgboost_ranker'); print(\"\\n\")\n",
    "\n",
    "# print(\"CatBoost Ranker:\") ; run_evaluation(df, target_week_range, weeks_before_target, training_window=250, method='catboost_ranker'); print(\"\\n\")\n",
    "\n",
    "# print(\"RNN:\") ; run_evaluation(df, target_week_range, weeks_before_target, training_window=500, method='rnn'); print(\"\\n\")\n",
    "\n",
    "# print(\"LSTM:\") ; run_evaluation(df, target_week_range, weeks_before_target, training_window=500, method='lstm'); print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all data from json file\n",
    "with open('long_term_results.json', 'r') as f:\n",
    "    long_term_results = json.load(f)\n",
    "\n",
    "print(long_term_results)\n",
    "\n",
    "# Calculate the mean of MAEs for each recipe (method)\n",
    "mean_maes = {\n",
    "    recipe: np.mean([item['average_mean_absolute_error'] for item in values])\n",
    "    for recipe, values in long_term_results.items()\n",
    "}\n",
    "\n",
    "# Sort the methods by the mean of MAEs in descending order\n",
    "sorted_methods = sorted(mean_maes.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Initialize the plot\n",
    "plt.figure(figsize=(15, 6))\n",
    "colormap = plt.colormaps.get_cmap('tab20')\n",
    "colors = colormap(np.linspace(0, 1, len(sorted_methods)))\n",
    "for i, (recipe, _) in enumerate(sorted_methods):\n",
    "    values = long_term_results[recipe]\n",
    "    weeks = [item['week_before_target'] for item in values]\n",
    "    errors = [item['average_mean_absolute_error'] for item in values]\n",
    "    \n",
    "    plt.plot(weeks, errors, marker='x', label=f\"{recipe} (Mean MAE: {mean_maes[recipe]:.4f})\", color=colors[i])\n",
    "\n",
    "plt.xlabel('Week Before Target')\n",
    "plt.ylabel('Average Mean Absolute Error')\n",
    "plt.title('Combined Plot of Average MAEs Across Weeks for All Long Term Methods')\n",
    "plt.gca().invert_xaxis()\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-env-harshal-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
